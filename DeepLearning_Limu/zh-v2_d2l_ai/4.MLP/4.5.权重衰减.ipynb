{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386828a0-516f-4fbf-b9d7-4bd87b050d91",
   "metadata": {},
   "source": [
    "## 4.5.权重衰减\n",
    "\n",
    "限制特征的数量是缓解过拟合的一种常用技术。\n",
    "\n",
    "但仅仅通过简单的限制特征数量（在多项式回归中体现为限制阶数），可能仍然使模型在过简单和过复杂中徘徊， 我们需要一个更细粒度的工具来调整函数的复杂性，使其达到一个合适的平衡位置。\n",
    "\n",
    "在训练参数化机器学习模型时， 权重衰减（weight decay）是最广泛使用的正则化的技术之一， 它通常也被称为$L_2$\n",
    "正则化这项技术通过函数与零的距离来衡量函数的复杂度。\n",
    "\n",
    "$$L(\\mathbf{w}, b) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2$$\n",
    "\n",
    "- $L_2$正则化线性模型=>岭回归（ridge regression）算法\n",
    "  - 对权重向量的大分量施加了巨大的惩罚，使得我们的学习算法偏向于**在大量特征上均匀分布权重**的模型\n",
    "- $L_1$正则化线性回归=>套索回归（lasso regression）\n",
    "  - 导致模型将权重**集中在一小部分特征**上， 而将其他权重清除为零\n",
    "  - **特征选择（feature selection）**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a77b3-3547-4857-bb96-26894d2afa0a",
   "metadata": {},
   "source": [
    "### 4.5.4.小结\n",
    "\n",
    "正则化是处理过拟合的常用方法：在训练集的损失函数中加入惩罚项，以**降低学习到的模型的复杂度**。\n",
    "\n",
    "保持模型简单的一个特别的选择是$L_2$用\n",
    "惩罚的权重衰减。这会导致学习算法更新步骤中的权重衰减。\n",
    "\n",
    "权重衰减功能在深度学习框架的优化器中提供。\n",
    "\n",
    "在同一训练代码实现中，不同的参数集可以有不同的更新行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f9c41-ce24-4048-b0c9-c0f839d8421b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
