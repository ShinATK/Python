{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312d4f17-7fef-487b-a414-2aa477da02d8",
   "metadata": {},
   "source": [
    "## 4.6. 暂退法（Dropout）\n",
    "\n",
    "希望模型深度挖掘特征，即将其权重分散到许多特征中， 而不是过于依赖少数潜在的虚假关联。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c895754-2974-4979-acfe-8baddb6237d4",
   "metadata": {},
   "source": [
    "### 4.6.1. 重新审视过拟合\n",
    "\n",
    "泛化性和灵活性之间的这种基本权衡被描述为偏差-方差权衡（bias-variance tradeoff）\n",
    "\n",
    "线性模型有很高的偏差：它们**只能表示一小类函数**。然而这些模型的方差很低：它们在**不同的随机数据**样本上可以得出**相似**的结果\n",
    "\n",
    "深度神经网络位于偏差-方差谱的另一端.神经网络并不局限于单独查看每个特征，而是**学习特征之间的交互**\n",
    "\n",
    "**深度网络的泛化性质令人费解，而这种泛化性质的数学基础仍然是悬而未决的研究问题。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e4913-b9b6-41a0-8e13-9873fd7d7634",
   "metadata": {},
   "source": [
    "### 4.6.2. 扰动的稳健性\n",
    "\n",
    "“好”的预测模型能在未知的数据上有很好的表现： 经典泛化理论认为，为了缩小训练和测试性能之间的差距，应该以简单的模型为目标。*简单性以较小维度的形式展现*\n",
    "\n",
    "简单性的另一个角度是**平滑性**，即**函数不应该对其输入的微小变化敏感**。\n",
    "\n",
    "1995年，克里斯托弗·毕晓普证明了 具有输入噪声的训练等价于Tikhonov正则化,用数学证实了“要求函数光滑”和“要求函数对输入的随机噪声具有适应性”之间的联系。[Bishop, 1995](https://doi.org/10.1162/neco.1995.7.1.108)\n",
    "在2014年，斯里瓦斯塔瓦等人 ([Srivastava et al., 2014](https://www.researchgate.net/publication/286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting)) 就如何将毕晓普的想法应用于网络的内部层提出了一个想法： 在训练过程中，他们建议在计算后续层之前向网络的每一层注入噪声。 因为当训练一个有多层的深层网络时，注入噪声只会在输入-输出映射上增强平滑性。\n",
    "\n",
    "**暂退法（dropout）**：前向传播中，在每一层的输入中增加噪声。\n",
    "从表面上看是在训练过程中丢弃（drop out）一些神经元。 在整个训练过程的每一次迭代中，标准暂退法包括在计算下一层之前将当前层中的一些节点置零。\n",
    "\n",
    "**如何注入这种噪声**：一种无偏向（unbiased）的方式注入噪声。以概率$p$将节点活性值$h$用$h'$代替，其中$\\mathrm{P}(h'=0)=p,\\ \\mathrm{P}(h'=\\frac{h}{1-p})=1-p$。计算期望值可得：$E[h']=h$，所以此种注入噪声方式可以保证其期望值不发生改变。\n",
    "\n",
    "**根据指定的暂退概率随机丢弃上一层的输出（相当于下一层的输入）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cac7f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4.6.3.实践中的暂退法\n",
    "\n",
    "通常，我们**在测试时不用暂退法**。 给定一个训练好的模型和一个新的样本，我们不会丢弃任何节点，因此不需要标准化。\n",
    "\n",
    "例外：一些研究人员在测试时使用暂退法， 用于估计神经网络预测的“不确定性”： 如果通过许多不同的暂退法遮盖后得到的预测结果都是一致的，那么我们可以说网络发挥更稳定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7c3312",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    # 在本情况中，所有元素都被丢弃\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(X)\n",
    "    # 在本情况中，所有元素都被保留\n",
    "    if dropout == 0:\n",
    "        return X\n",
    "    mask = (torch.rand(X.shape) > dropout).float() # 实现dropout的关键\n",
    "    return mask * X / (1.0 - dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f358108f-9454-4b7b-bacf-961d6aa393d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0., 12.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0., 28., 30.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "X= torch.arange(16, dtype = torch.float32).reshape((2, 8))\n",
    "print(X)\n",
    "print(dropout_layer(X, 0.))\n",
    "print(dropout_layer(X, 0.5))\n",
    "print(dropout_layer(X, 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768a401-a0d4-44b6-89dd-5445fdd1e594",
   "metadata": {},
   "source": [
    "### 4.6.6. 小结\n",
    "\n",
    "暂退法在前向传播过程中，计算每一内部层的同时丢弃一些神经元。\n",
    "\n",
    "暂退法可以避免过拟合，它通常与控制权重向量的维数和大小结合使用的。\n",
    "\n",
    "暂退法$h$活性值\n",
    "替换为$h$有期望值\n",
    "的随机变量。\n",
    "\n",
    "暂退法仅在训练期间使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fa4a1-471e-45b3-91a3-be8a107d9bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
