{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4.4. 模型选择、欠拟合和过拟合\n",
    "\n",
    "作为机器学习科学家，我们的目标是发现模式（pattern）。\n",
    "\n",
    "**如何才能确定模型是真正发现了一种泛化的模式， 而不是简单地记住了数据呢？**\n",
    "\n",
    "当我们*使用有限的样本*时，可能会遇到这样的问题： 当*收集到更多的数据*时，会发现之前找到的明显关系并不成立。\n",
    "\n",
    "将模型在*训练数据*上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting）， 用于对抗过拟合的技术称为正则化（regularization）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4.4.1. 训练误差和泛化误差\n",
    "\n",
    "训练误差（training error）是指， 模型在**练数据集**上计算得到的误差。\n",
    "\n",
    "泛化误差（generalization error）是指， 模型**应用在同样从原始样本的分布中抽取的无限多数据样本**时，模型误差的期望。\n",
    "\n",
    "在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差， 该测试集由随机选取的、未曾在训练集中出现的数据样本构成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1.2. 模型复杂性\n",
    "\n",
    "重点介绍几个倾向于影像模型泛化的因素：\n",
    "\n",
    "1. 可调整参数的数量。当可调整参数的数量（自由度）很大时，模型往往更容易过拟合。\n",
    "2. 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。\n",
    "3. 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万样本的数据集则需要一个极其灵活的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2.2 K折交叉验证\n",
    "\n",
    "原始训练数据被分成$K$个不重叠的子集。然后执行$K$次模型训练和验证，每次在$K-1$个子集上进行训练，并在剩余的一个子集上进行验证。最后，通过对$K$次实验的结果取平均来估计训练和验证误差。证误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3. 欠拟合还是过拟合？\n",
    "\n",
    "1. 训练误差和验证误差都很严重， 但它们之间仅有一点差距。\n",
    "\n",
    "   如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足）， 无法捕获试图学习的模式。 此外，由于我们的训练和验证误差之间的泛化误差很小， 我们有理由相信可以用一个更复杂的模型降低训练误差。 这种现象被称为欠拟合（underfitting）。\n",
    "\n",
    "2. 当我们的训练误差明显低于验证误差时要小心， 这表明严重的过拟合（overfitting）。\n",
    "\n",
    "   过拟合并不总是一件坏事。 特别是在深度学习领域，众所周知， 最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3.1. 模型复杂性\n",
    "#### 4.4.3.2. 数据集大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.5. 小结\n",
    "\n",
    "欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差。\r\n",
    "\r\n",
    "由于不能基于训练误差来估计泛化误差，因此简单地最小化训练误差并不一定意味着泛化误差的减小。机器学习模型需要**注意防止过拟合，即防止泛化误差**过大。\r\n",
    "\r\n",
    "验证集可以用于模型选择，但不能过于随意地使用它。\r\n",
    "\r\n",
    "我们**应该选择一个复杂度适当的模型，避免使用数量不**足的训练样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
