[[【Think】计算机视觉入门路线]]

## 第一步：统计学习方法

**学习内容**：关于模型的一些基本概念，简单的几个模型：感知机、回归模型、判别模型等。  

**学习程度**：

1. 了解[[1_统计学习方法的三要素：模型、策略和算法]]、[[1_模型评估：训练误差和测试误差]]、[[1_模型选择：正则化与交叉验证]]；

2. 了解[[2_生成模型与判别模型]]；

3. 了解感知机、回归模型、分类模型，了解它们的区别，原理即可；

4. 熟悉泛化能力、分类问题、标注问题等；

**学习方式**：阅读《统计学习方法》李航版第一章、第二章即可，后面的先不急着去看。

**学习目的**：主要是了解什么是模型、有哪些模型、模型的性能影响等基本知识面。

- 把握如何分析一个模型的泛化能力，学会区分过拟合欠拟合，如何评估一个模型等

---

## 第二步：深度学习基础

**学习内容**：卷积神经网络的组成、原理。  

**学习程度**：

1. 了解卷积的作用，卷积的过程、优缺点，几种常见的卷积方式如转置卷积、空洞卷积、分组卷积、1x1卷积，可变形卷积等；

2. 了解归一化的常用方法、作用、原理；

3. 最大池化和平均池化的作用、区别、原理、前传后传是如何完成的、各自的应用场合；

4. 常见的激活函数、特点、各自适用的场合；

5. 了解正则化常用方法、原理、作用、特点、优缺点；

6. 了解常见的损失函数、特点、各自适用的场合；

7. 了解反向传播的原理，手动推导一个三层的卷积神经网络；

8. 了解梯度下降原理、常见的优化方式；

**学习方式**：B站李宏毅的深度学习课程，这个课程内容很多，可以只看上面的这一部分内容，剩下的可以不急着去看。也可以看一看《解析卷积神经网络手册》或邱锡鹏的《神经网络与深度学习》。在公众号CV技术指南中也有很多相关的总结文章，例如《池化技术总结》《神经网络中的归一化方法总结》等，大家可以去找找。

**学习目的**：了解基本的神经网络组成、原理，了解各种基本的损失函数、激活函数、归一化方法、正则化方法、池化方法等。

在学完上面这里后，开始搞点应用，找找成就感。学一学如何搭建这样一个神经网络

---

## 第三步：使用Pytorch搭建卷积神经网络

**学习内容**：学会pytorch的使用，学会一个完整的模型由什么组成，建立计算机视觉的知识体系。  

**学习程度**：

1. 了解一个完整的模型由哪些部分组成，各自的作用是什么。

2. 学会如何自定义classdataset，了解数据读取的流程，学会如何预处理。

3. 学会如何搭建一个基本的卷积神经网络。

4. 学会如何编写训练过程，学会加载预训练模型，设置学习率设置优化方式等。

5. 学会如何推理，训练实时可视化，解析参数等。

**学习方式**：阅读公众号CV技术指南的《从零搭建Pytorch模型教程》系列文章，阅读完对整体模型有一定了解后，去github找一个简单的卷积神经网络项目，看看别人是如何写的，然后自己动手搭建一个分类猫狗的模型，所有代码都必须自己完成，具体某一部分不会写可以百度搜索怎么写。

**学习目的**：学会自己搭建一个完整的模型，了解一个模型是如何实现的，了解计算机视觉大概是怎么一回事，形成基本的认知，找到成就感。

下面就开始回过头补一点基础，先学一个数字图像处理和opencv，再了解一下计算机视觉的传统方法。

---

## 第四步：数字图像处理与opencv

**学习内容**：了解图像的一些基本知识，了解计算机视觉的传统解决方法，学会图像处理。  

**学习程度**：

1. 学会基本的图像读取、保存、裁剪、转灰度、视频读取、保存等操作。

2. 学会图像处理中的基础操作、算数运算、图像阈值、平滑、滤波、形态学处理、梯度、边缘检测、轮廓检测等。

3. 学会直方图、图像增强、hough变换、分水岭算法、角点检测等。

4. 学会传统特征提取方法，也即传统特征描述子，如HOG, SIFT, SURF, BRIEF, ORB等。

5. 学会视频分析中的光流，meanshift, camshift等。

6. 学会以上所有内容在opencv中的实现。

**学习方式**：主要阅读《Opencv-Python-Tutorial中文教程》和数字图像处理教材即可，一般推荐冈萨雷斯版的，也可以去mooc上看浙江大学的关于数字图像处理的课程。

**学习目的**：大部分学计算机视觉的人都是直接上手深度学习，已经很少有人能静下心来学一学图像处理和传统解决方法了，这个对于理解计算机视觉会有比较大的帮助，在数据读取过程中，也需要进行数据预处理等操作。

---

## 第五步：高校阅读英文文献的方法

**学习内容**：具备阅读英文文献的能力，掌握高效、高速阅读英文文献的方法。  

**学习方法**：

1. **打印下来阅读**，碰到不认识的单词就去百度或谷歌翻译，手动输入搜索，然后记在笔记软件里。副词，形容词也都需要，不只是专业性术语。很多时候副词是表程度的，对于理解论文也是很重要。

2. **每天看一看那些记录下来的单词**。注意：不是背，瞄几眼就可以了。这是因为你在论文中就碰到了，有个具体的语义环境，再手动输入了一次，再经常看了它几眼，基本就记住了。

3. **坚持住**，不用很久，大概也就一个月不到，基本就可以做到无障碍阅读论文了。虽然此时仍然会出现不认识的单词，但基本很少，几乎不影响阅读了。

在这个阶段建议论文的每一行都去阅读，这个过程会了解论文由哪些部分组成，哪些地方是重点，哪些是细节，哪些是概括内容。

不要觉得这样学习很慢，一个星期都看不完一篇论文，这其实就是一个磨刀不误砍柴功的道理。当具备这种直接阅读论文的能力后，自然就知道哪些内容要跳过没必要关注，哪些是重点，可以认真理解，哪些是概括的，可以知道这篇论文大概是怎样的。然后才可以做到高速阅读、高效阅读、高效理解。

**学习目的**：就一句话，别的方向不清楚，就计算机视觉而言，看个论文都还要用翻译软件，还学个屁？因此这一步没掌握，后面的基本可以不用学了。学习计算机视觉需要大量阅读论文，用翻译软件速度太慢，效果非常低，翻译结果也很容易给理解造成困难。此外，那些从不看论文而仅仅通过看别人博客学计算机视觉的人我相信都没什么水平。最前面提到，计算机视觉是一门玄学，需要有深入的理解，只有通过阅读论文中才能真正产生对这个内容的理解，后面自己搞项目或论文时才能有深入的见解。

---

## 第六步：卷积神经网络进阶

**学习内容**：学习现有的经典卷积神经网络、轻量化网络，了解它们的设计思路，设计原则。  

**学习程度**：

1. 熟悉所有现有的经典卷积神经网络，如AlexNet，NiN，VGG，GoogLeNet，Inception系列，ResNet系列，DenseNet等，了解它们的设计思路，设计原则。

2. 熟悉所有现有的轻量化网络，如Xception，MobileNet系列，ShuffleNet系列，SqueezeNet，GhostNet，EfficientNet等。

**学习方式**：第一原则，建议大家去阅读原论文，且直接看英文版的，不要用翻译软件。在看完后建议大家按照时间顺序，把以上网络写一个综述，详细介绍每一个网络的组成、设计思路、设计原则等。

**学习目的**：很多人对这方面也是不清楚的，仅仅了解一个ResNet和VGG如何使用，其它的设计原则也不懂，设计思路也不懂。在自己阅读完原论文，并写完综述后，基本对卷积神经网络已经有了非常深刻的认识和理解了。在日后自己设计新模块的时候，才不会是胡乱设计。且解释为何这么设计时也能有比较合理的解释。

推荐的是**目标检测方向**：
- 一是因为这个方向是处理图像分类以外最简单的；
- 二是最实用的，几乎所有应用中都需要用到检测；
- 三是因为它是目前落地应用最广的；
- 四是因为它很多的设计思想在其它方向都有体现；
- 五是因为目标检测是将来面试找工作时几乎必问的内容。

---

## 第七步：目标检测

**学习内容**：了解计算机视觉的具体是如何应用的，如何根据这个应用创新改进模型的。  

**学习程度**：

1. 了解目标检测的传统检测算法

2. 熟悉RCNN系列发展演变，设计思路，改进思路，优缺点

3. 熟悉YOLO系列发展演变，设计思路，改进思路，优缺点

4. 熟悉anchor-free系列发展，设计思路，优缺点。

5. 熟悉IoU系列的改进思路，NMS的基本实现和改进思路。

6. 熟悉目标检测中的常用技术，如特征金字塔，注意力机制等。

7. 熟悉目标检测中的评估指标，如FPS，mAP，召回率，ROC曲线，precision和accuracy等，熟悉这些指标的计算方式。

8. 具备复现其中任意一个模型的能力。

**学习方式**：每个模型都要去看原论文，一定一定不要先看别人的解读的博客，实在看不懂的地方再看博客。看懂了后还是要接着看原论文。在每了解一个系列后，就将其发展演变的过程、设计思路，优缺点都写成综述文章，日后定有大用。学习过程中，结合第三步搭建神经网络模型的内容，要多去看看作者提供的代码，少去看别人写的代码解析。

**学习目的**：彻底了解计算机视觉的研究是怎样的，是怎样设计的，是怎样改进的。同时提醒一句，如果对目标检测都不了解，几乎等于没学过计算机视觉。很多到研究生阶段才开始学计算机视觉的人，都是没有时间和机会去学目标检测的，这实在不应该。

---

## 第八步：回顾基础、学习机器学习模型

**学习内容**：重新回顾第二步中学过的内容，学习机器学习中其它模型  

**学习程度**：

1. 对第二步中所有内容要非常熟悉。

2. 了解《统计学习方法》中的剩余模型。其中重点把握SVM、聚类，其它的仅了解基本原理、应用场合、优缺点即可。公式什么的可以过一下，但不用特意去推导，没啥用。

3. 《统计学习方法》中附录部分的梯度下降法、牛顿法和拟牛顿法、拉格朗日对偶性这些可以多了解了解。

**学习方式**：学的过程中，公式都可以去过一轮，但没必要手推导一遍，也不需要去代码实现。重点把握基本原理、应用场合、优缺点。

**学习目的**：这些内容说重要不重要，基本用不到，但完全不知道也不好，很多内容对于思维能力的扩展，知识面的扩展很重要。如果某一天，你反感了神经网络的这种模型，突发奇想设计了一种新的，兴奋地向别人介绍，结果最后别人告诉你这是机器学习中一种现成的模型，例如adaboost，自己想像去。

---

## 第九步：深度学习的其它基础

**学习内容**：学习GAN、编码器、循环神经网络，自监督、无监督，少样本学习，元学习、迁移学习、知识蒸馏、图神经网络、图卷积神经网络等。  

**学习程度**：

1. 熟悉GAN的基本原理、基本模型、训练过程、应用场合等。

2. 熟悉编码器基本原理、基本模型、应用场合等。

3. 熟悉RNN、LSTM的基本原理，优缺点等。

4. 了解自监督、无监督的基本原理，常用模型等。

5. 熟悉少样本学习、元学习基本原理，常用方法等。

6. 熟悉迁移学习、知识蒸馏基本原理、常用方法等。

7. 了解图神经网络、图卷积神经网络基本原理、常用方法等。

**学习方式**：这些方面的内容直接去找相关的综述文章看看即可，不需要去看论文。比较重要的是GAN、编码器、迁移学习、知识蒸馏，这几个非常有可能在日后的研究方向中看到的，其它的都不是特别重要。这些都不需要自己去写代码实践。

**学习目的**：扩展知识面，巩固基础。和机器学习那里的目的一样，避免无知而引发的出洋相。

---

## 第十步：计算机视觉的进阶

**学习内容**：总结深度学习中、神经网络中各种技术。了解一些热门方向的研究现状、基本模型、涉及到的技术、创新设计的思路，如语义分割、实例分割，目标跟踪，行人重识别，行为识别，3DCNN模型，视频中的一些检测，Transformer模型。  

**学习程度**：

1. 总结数据增强方法、注意力机制、特征金字塔、归一化方法、损失函数等。

2. 掌握Tensforflow框架的使用、具备看懂Caffe框架项目的能力。

3. 了解CNN可视化技术，如特征图可视化、热力图可视化等。这个必须要会写代码。

4. 了解语义分割、实例分割、目标跟踪，行人重识别，行为识别，3DCNN模型，视频中的一些检测，Transformer模型等研究方向的经典论文、创新设计思路，优缺点等。

**学习方式**：多看论文，多看公众号发的论文分享等，以往的一些经典论文也要去找出来看看原论文。对于Transformer，需要有非常深刻的理解，多去看论文和别人的解读。公众号CV技术指南中有非常多关于Transformer的论文解读，可以找出来全看看，并且实现代码也要具备。

**学习目的**：扩展知识面，提高创新能力，加深对计算机视觉的理解，为搞论文和做项目做知识储备。

---

## 第十一步：技术路线

**学习内容**：学习神经网络量化、混合精度训练、模型部署等相关方面的技术，阅读一些框架的底层实现源码等。  

模型部署相关框架：TVM、TensorRT、CUDA、OpenVINO、MNN、Oneflow、libtorch等

目标检测方面的框架：OpenMMLab，Detectron

可以去阅读底层源码的框架：Pytorch，Caffe。

---

