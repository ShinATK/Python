
朴素贝叶斯 naive Bayes
- 基于**贝叶斯定理**与**特征条件独立假设**的*分类方法*
- 对于给定的训练数据集：
	- 基于特征条件独立，假设输入与输出的联合概率分布
	- 基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y

本章，朴素贝叶斯法：
- 朴素贝叶斯法的学习与分类
- 朴素贝叶斯法的参数估计算法

> **朴素贝叶斯法**与**贝叶斯估计 Bayesian estimation** 是不同概念

## 4.1 朴素贝叶斯法的学习与分类

### 4.1.1 基本方法

- 输入空间：$\mathcal{X} \subseteq \mathbf{R}^n$ 为 $n$ 维向量的集合；
	- 输入：特征向量 $x \in \mathcal{X}$
	- $X$ 定义在输入空间 $\mathcal{X}$ 上的随机向量
- 输出空间：类标记集合 $\mathcal{Y} = \{ c_1, c_2, ..., c_K \}$
	- 输出：类标记 class label，$y \in \mathcal{Y}$
	- $Y$ 定义在输入空间 $\mathcal{Y}$ 上的随机变量
- 联合概率分布：$P(X, Y)$
- 训练数据集（由 $P(X, Y)$ 独立同分布产生）：$$T = \{ (x_1, y_1), (x_2, y_2), ..., (x_N, y_N) \}$$

**朴素贝叶斯法**：通过训练数据集学习联合概率分布 $P(X, Y)$
1. 学习先验概率分布：$$P(Y=c_k), \  k=1,2,...,K$$
2. 学习条件概率分布：$$P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)},X^{(12)}=x^{(2)},...,X^{(n)}=x^{(n)}|Y=c_k), \ k=1,2,...,K$$
3. 假设：条件独立性 $$\begin{align}
P(X=x|Y=c_k) &= P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)|Y=c_k} \\
&= \prod^{n}_{j=1} P(X^{(j)} = x^{(j)}|Y=c_k)
\end{align}$$
4. 得到联合概率分布 $P(X, Y)$

> 朴素贝叶斯法：学习到**生成数据的机制**，属于生成模型
> **条件独立性假设**：用于**分类的特征**在**类确定**的条件下都是**条件独立**的。但会牺牲一定的分类准确率

5. 计算后验概率分布（**朴素贝叶斯法分类的基本公式**） $$\begin{align}
P(Y=c_k|X=x) &= \frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum\limits_k P(X=x|Y=c_k)P(Y=c_k)} \\
&= \frac{P(Y=c_k)\prod\limits_{j} P(X^{(j)} = x^{(j)}|Y=c_k)}{\sum\limits_k P(Y=c_k)\prod\limits_{j} P(X^{(j)} = x^{(j)}|Y=c_k)}
\end{align}$$
6. **朴素贝叶斯分类器**可表示为（对于任意 $c_k$ 分母相同）：$$\begin{align}
y &= f(x) \\ &= \arg\max\limits_{c_k} P(Y=c_k|X=x) \\
&= \arg\max\limits_k P(Y=c_k)\prod\limits_j P(X^{(j)} = x^{(j)}|Y=c_k)
\end{align}$$

### 4.1.2 后验概率最大化的含义

朴素贝叶斯法将实例分类到后验概率最大的类中。

- 等价于期望风险最小化
- 证明：[[后验概率最大化的含义]]


## 4.2 朴素贝叶斯法的参数估计

### 4.2.1 极大似然估计

- 先验概率 $P(Y=c_k)$ 的极大似然估计：$$P(Y=c_k)=\frac{\sum\limits^N_{i=1}I(y_i=c_k)}{N}, \ k=1,2,...K$$
- 设第j个特征 $x^{j}$ 可能的取值集合为 ${a_{j1},...,a{jS_j}}$
- 条件概率 $P(X^{(j)}=a_{jl}|Y=c_k)$ 的极大似然估计：$$P(X^{(j)}=a_{jl}|Y=c_k) = \frac{\sum\limits^N_{i=1}I(x_i^{(j)}=a_{jl}|y_i=c_k)}{\sum\limits^N_{i=1}I(y_i=c_k)}$$
	- 式中， $x^{j}$ 是第i个样本的第j个特征； $a_{jl}$ 是第j个特征可能取的第$l$个值；$I$为指示函数

### 4.2.2 学习与分类算法

**算法4.1 朴素贝叶斯算法 naive Bayes algorithm**
- ![[Pasted image 20231105131936.png]]
- （1）计算先验概率及条件概率
	- 先验概率：$P(Y=c_k)=\frac{\sum\limits^N_{i=1} I(y_i=c_k)}{N}$
	- 条件概率：$P(X^{(j)}=a_{jl}|Y=c_k) = \frac{\sum\limits^N_{i=1}I(x_i^{(j)}=a_{jl}|y_i=c_k)}{\sum\limits^N_{i=1}I(y_i=c_k)}$
- （2）对于给定的实例 $x = (x^1,x^2m...,x^n)^T$，计算：$P(Y=c_k)\prod\limits^n_{j=1}P(X^j=x^j|Y=c_k)$
- （3）确定实例$x$的类：$$y=\arg\max\limits_{c_k}P(Y=c_k)\prod^n_{j=1}P(X^j=x^j|Y=c_k)$$
