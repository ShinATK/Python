## 极大似然估计

[# 极大似然估计](https://zh.wikipedia.org/zh-hans/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1)


**极大似然估计（maximum likelihood estimation, MLE）**：用来估计一个概率模型参数的一种方法。*一个重要假设：所有的采样都是独立同分布的*

利用已知样本结果信息，反推最有可能（最大概率）导致这些样本结果出现的模型参数值。




“似然函数”likelihood$$L(\theta)=P(x|\theta)$$
当模型参数为$\theta$时，观测到数据$x$的概率

对于这个函数：

$P(x|\theta)$

输入有两个：$x$表示某一个具体的数据；$\theta$表示模型的参数。

如果$\theta$是已知确定的，$x$是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。

如果$x$是已知确定的，$\theta$是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。


## [最大后验估计](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation)

![[Pasted image 20230806213359.png]]

贝叶斯统计学中，“**最大后验概率估计（Maximum A Posteriori Estimation, MAP）**”，是后验概率分布的众数。

**贝叶斯定理 Bayes's Theorem**：是概率论中的一个定理，描述在已知一些条件下，某事件的发生几率。

通常，事件A在事件B已经发生的条件下发生的概率，与事件B在事件A已经发生的条件下发生的概率是不一样的，但二者是有确定关系的，贝叶斯定理就是这种关系的陈述。

公式为：$$P(A|B)=\frac{P(A)P(B|A)}{P(B)}$$
其中：
- $P(A|B)$是已知B发生后，A的条件概率，也称为A的*事后概率*
- $P(A)$是A的*先验概率/边缘概率*
- $P(B|A)$是已知A发生后，B的条件概率。也可以称为B的*事后概率*。也可以称为在特定B时，A的*似然性*
- $P(B)$是B的*先验概率*

由贝叶斯公式有：$$P(\theta|X)=\frac{P(\theta)P(X|\theta)}{P(X)} \propto P(\theta)P(X|\theta)$$
其中，$\theta$为随机变量。

**极大似然估计中要估计的参数$\theta$是一般变量，而贝叶斯估计中要估计的参数$\theta$是个随机变量**


