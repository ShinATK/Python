## 经验风险最小化

**经验风险最小化（empirical risk minimization，ERM）**：经验风险最小的模型就是最优的模型。$$\min\limits_{f\in \mathcal{F}}\frac{1}{N}\sum\limits^N_{i=1}L(y_i,f(x_i))$$

样本容量足够大时，经验风险最小化能保证有很好的学习效果。

[[极大似然估计与最大后验估计]]中的**极大似然估计，maximum likelihood estimation MLE**就是风险最小化的一个例子。

*当模型是条件概率分布、损失函数是对数函数时，经验风险最小化就等价于极大似然估计*


## 结构风险最小化

**结构风险最小化（structural risk minimization, SRM）**：为了防止过拟合而提出来的策略。

结构风险最小化等价于正则化（regularization）$$\min\limits_{f\in \mathcal{F}}\frac{1}{N}\sum\limits^N_{i=1}L(y_i,f(x_i))+\lambda J(f)$$

结构风险在经验锋线上加上表示模型的复杂度的正则化项（regularizer）或罚项（penalty term）。



贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation, MAP，[[极大似然估计与最大后验估计]]）就是结构风险最小化的一个例子。

*当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计*（对数应该是因为上边公式中的$\lambda J(f)$，可以看成是取log后提取出来的加和项）